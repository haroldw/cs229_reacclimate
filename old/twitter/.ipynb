{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (3.7.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (2.21.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.2.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\n",
      "Requirement already satisfied: pandas in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already up-to-date: textblob in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from textblob) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: preprocessor in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (1.1.3)\n",
      "Requirement already satisfied: tweet-preprocessor in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied: sklearn in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "Requirement already satisfied: argparse in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already up-to-date: nltk in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Collecting pycontractions\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/ca/61b0fa2eb9f9fcc13f4a68c517b00ab000f859782492dd7a62032583ecb2/pycontractions-2.0.0.tar.gz\n",
      "Collecting gensim>=2.0 (from pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/e80eea8c6c04a0b845c2c9c298914025f2b974075c7514aa8464c9bb4adb/gensim-3.7.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7MB 15.0MB/s eta 0:00:01     |█████████████████████████▊      | 19.8MB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting language_check>=1.0 (from pycontractions)\n",
      "  Downloading https://files.pythonhosted.org/packages/97/45/0fd1d3683d6129f30fa09143fa383cdf6dff8bc0d1648f2cf156109cb772/language-check-1.1.tar.gz\n",
      "Collecting pyemd>=0.4.4 (from pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/c5/7fea8e7a71cd026b30ed3c40e4c5ea13a173e28f8855da17e25271e8f545/pyemd-0.5.1.tar.gz (91kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 15.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.7.0 (from gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/ba/7eaf3c0dbe601c43d88e449dcd7b61d385fe07c0167163f63f58ece7c1b5/smart_open-1.8.3.tar.gz (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 19.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from gensim>=2.0->pycontractions) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from gensim>=2.0->pycontractions) (1.16.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from gensim>=2.0->pycontractions) (1.12.0)\n",
      "Collecting boto>=2.32 (from smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 39.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=2.0->pycontractions) (2.21.0)\n",
      "Collecting boto3 (from smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/92/b72cac312331724b7d2fb6d9f5c6045cc4b4ba71f64ce5bbc601fee1adc7/boto3-1.9.138-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 30.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim>=2.0->pycontractions) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim>=2.0->pycontractions) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim>=2.0->pycontractions) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim>=2.0->pycontractions) (2.8)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/de/5737f602e22073ecbded7a0c590707085e154e32b68d86545dcc31004c02/s3transfer-0.2.0-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.138 (from boto3->smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/ba/490ac1a96c3f8ab85217c037f6781fca7953c887ba716e6c46f5c3075212/botocore-1.12.138-py2.py3-none-any.whl (5.4MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4MB 19.0MB/s eta 0:00:01     |██████████████████████          | 3.7MB 19.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.138->boto3->smart-open>=1.7.0->gensim>=2.0->pycontractions) (2.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.138->boto3->smart-open>=1.7.0->gensim>=2.0->pycontractions)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K     |████████████████████████████████| 552kB 22.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycontractions, language-check, pyemd, smart-open\n",
      "  Building wheel for pycontractions (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/User/Library/Caches/pip/wheels/52/5c/7d/8c9b47574380b68f7efdd637657f135ca143ea0ba4ade3b296\n",
      "  Building wheel for language-check (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/User/Library/Caches/pip/wheels/d5/46/82/90a89c23eac1837364ed7217a9eed71bc9e6ad4825be93968e\n",
      "  Building wheel for pyemd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/User/Library/Caches/pip/wheels/e4/ba/b0/1f4178a35c916b22fc51dc56f278125d4b8cfb0592e5f0cc24\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/User/Library/Caches/pip/wheels/b8/cb/43/c0ba52baf2b0e371ec1d5b2d4685d6d24617b1391f3eeacda5\n",
      "Successfully built pycontractions language-check pyemd smart-open\n",
      "Installing collected packages: boto, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim, language-check, pyemd, pycontractions\n",
      "Successfully installed boto-2.49.0 boto3-1.9.138 botocore-1.12.138 docutils-0.14 gensim-3.7.2 jmespath-0.9.4 language-check-1.1 pycontractions-2.0.0 pyemd-0.5.1 s3transfer-0.2.0 smart-open-1.8.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tweepy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install -U textblob\n",
    "!{sys.executable} -m pip install preprocessor\n",
    "!{sys.executable} -m pip install tweet-preprocessor\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install argparse\n",
    "!{sys.executable} -m pip install -U nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import os\n",
    "import sklearn\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor.api as p\n",
    "import argparse\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = 'Lydypy5GRHslhuWsXTAagVFpO'\n",
    "consumer_secret = 'K9HA6MyfRWm73G50WHvzBPxfY0gWfJRk5ajcUmGRCg4e9NiM69'\n",
    "access_key= '789687511-BGbhUzj8zVLk9HeKKxrCZnzJ21xb3qXqZMHyf0gX'\n",
    "access_secret = 'kIDmi6vhOiePyEIZ5XXrOV8rl0xLOe5wLQ2XbhH2qCLsr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#declare file paths as follows for three files\n",
    "democrat_tweets = \"/Users/User/221project/data/senate_democrat_data.csv\"\n",
    "republican_tweets = \"/Users/User/221project/data/senate_republican_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#columns of the csv file\n",
    "COLS = ['id','original_text', 'clean_text','polarity', 'subjectivity', 'hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    " \n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "#after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    tweet = re.sub(r'RT *[^:]*:','', tweet);\n",
    "    #tweet = re.sub(r'[\\.@[a-zA-Z]*:]+','', tweet);\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#remove url\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = []\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in emoticons and w not in string.punctuation:\n",
    "            if w.isdigit():\n",
    "                continue\n",
    "            if w[0] == \".\":\n",
    "                continue\n",
    "            w = re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', w)\n",
    "            w = w.lower()\n",
    "            \n",
    "            if len(w) == 1 and w not in ['a', 'e', 'i','o','u']:\n",
    "                continue\n",
    "            elif len(w) == 2 and w[0] in string.punctuation:\n",
    "                continue\n",
    "            filtered_tweet.append(w.lower())\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"have not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he has\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how are\",\n",
    "\"i'd\": \"I would\",\n",
    "\"i'll\": \"I will\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she has\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there's\": \"there has\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"y'all\": \"you all\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()), flags = re.IGNORECASE)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0).lower()]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def write_tweets(handle, file):\n",
    "    #If the file exists, then read the existing data from the CSV file.\n",
    "    #if os.path.exists(file):\n",
    "        #df = pd.read_csv(file, header=0)\n",
    "   # else:\n",
    "        #df = pd.DataFrame(columns=COLS)\n",
    "    #page attribute in tweepy.cursor and iteration\n",
    "    for page in tweepy.Cursor(api.user_timeline, id=handle,\n",
    "                              count=200, include_rts=True, tweet_mode = 'extended').pages():\n",
    "        for status in page:\n",
    "            new_entry = []\n",
    "            status = status._json\n",
    "    \n",
    "            if \"retweeted_status\" in status:\n",
    "                status['full_text'] = status[\"retweeted_status\"]['full_text']\n",
    "            \n",
    "            original_tweet = status['full_text']\n",
    "            \n",
    "            status['full_text'] = status['full_text'].replace(\"&amp;\", \"and\")\n",
    "            status['full_text'] = status['full_text'].replace(\"#\", \"\")\n",
    "            status['full_text'] = status['full_text'].replace(\"’\", \"'\")\n",
    "            status['full_text'] = expand_contractions(status['full_text'])\n",
    "            \n",
    "            status['full_text'] = re.sub(r'\\.@[a-zA-Z]*:','',status['full_text']);\n",
    "            status['full_text'] = status['full_text'].replace(\".@\", \"\")\n",
    "            status['full_text'] = status['full_text'].replace(\"@\", \"\")\n",
    "            \n",
    "            clean_text = p.clean(status['full_text'])\n",
    "            clean_text =  status['full_text']\n",
    "            filtered_tweet=clean_tweets(clean_text)\n",
    "            \n",
    "            filtered_tweet = filtered_tweet.strip()\n",
    "            if len(filtered_tweet.split()) < 2:\n",
    "                continue\n",
    "\n",
    "            blob = TextBlob(filtered_tweet)\n",
    "            Sentiment = blob.sentiment     \n",
    "            polarity = Sentiment.polarity\n",
    "            subjectivity = Sentiment.subjectivity\n",
    "            \n",
    "            new_entry += [status['id'],filtered_tweet, \"dem\", original_tweet, polarity,subjectivity]\n",
    "            hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "            new_entry.append(hashtags) #append the hashtags\n",
    "        \n",
    "            with open(file, \"a+\", newline='') as fp:\n",
    "                wr = csv.writer(fp, dialect='excel')\n",
    "                wr.writerow(new_entry)\n",
    "    \n",
    "            #single_tweet_df = pd.DataFrame([new_entry], columns=COLS)\n",
    "            #df_final = df.append(single_tweet_df, ignore_index=True)\n",
    "            \n",
    "            #csvFile = open(file, 'a+' ,encoding='utf-8')\n",
    "            #df.to_csv(csvFile, mode='a', columns=COLS, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nrep_handle1 = \"SenateGOP\"\\nrep_handle2 = \"HouseGOP\"\\nrep_handle3 = \"realDonaldTrump\"\\nrep_handle4 = \"senatemajldr\"\\nrep_handle5 = \"SpeakerRyan\"\\nrep_handle6 = \"Heritage\"\\nrep_handle7 = \"GOPChairwoman\"\\nrep_handle8 = \"RepMattGaetz\"\\nrep_handle9 = \"marcorubio\"\\nrep_handle10 = \"WarrenDavidson\"\\nrep_handle11 = \"GOPLeader\"\\nrep_handle12= \"DLoesch\"\\nrep_handle13 = \"SteveScalise\"\\nrep_handle14 = \"March_For_Life\"\\nrep_handle15 = \"charliekirk11\"\\nrep_handle16 = \"SenatorTimScott\"\\nrep_handle17 = \"SenMcSallyAZ\"\\nrep_handle18 = \"TedCruz\"\\nrep_handle19 = \"KellyannePolls\"\\n\\nwrite_tweets(rep_handle1, tweets)\\nwrite_tweets(rep_handle2, tweets)\\nwrite_tweets(rep_handle3, tweets)\\nwrite_tweets(rep_handle4, tweets)\\nwrite_tweets(rep_handle5, tweets)\\nwrite_tweets(rep_handle6, tweets)\\nwrite_tweets(rep_handle7, tweets)\\nwrite_tweets(rep_handle8, tweets)\\nwrite_tweets(rep_handle9, tweets)\\nwrite_tweets(rep_handle10, tweets)\\nwrite_tweets(rep_handle11, tweets)\\nwrite_tweets(rep_handle12, tweets)\\nwrite_tweets(rep_handle13, tweets)\\nwrite_tweets(rep_handle14, tweets)\\nwrite_tweets(rep_handle15, tweets)\\nwrite_tweets(rep_handle16, tweets)\\nwrite_tweets(rep_handle17, tweets)\\nwrite_tweets(rep_handle18, tweets)\\nwrite_tweets(rep_handle19, tweets)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = \"/Users/User/221project/data/party_data2.csv\"\n",
    "\n",
    "senDems = \"SenateDems\"\n",
    "write_tweets(senDems, tweets)\n",
    "houseDems = \"HouseDemocrats\"\n",
    "write_tweets(houseDems, tweets)\n",
    "senSan = \"SenSanders\"\n",
    "write_tweets(senSan, tweets)\n",
    "aoc = \"AOC\"\n",
    "write_tweets(aoc, tweets)\n",
    "spel = \"SpeakerPelosi\"\n",
    "write_tweets(spel, tweets)\n",
    "schum = \"SenSchumer\"\n",
    "write_tweets(schum, tweets)\n",
    "khar = \"KamalaHarris\"\n",
    "write_tweets(khar, tweets)\n",
    "senWar = \"SenWarren\"\n",
    "write_tweets(senWar, tweets)\n",
    "corB = \"CoryBooker\"\n",
    "write_tweets(corB, tweets)\n",
    "aS = \"RepAdamSchiff\"\n",
    "write_tweets(aS, tweets)\n",
    "jb = \"JoeBiden\"\n",
    "write_tweets(jb, tweets)\n",
    "hrc = \"HillaryClinton\"\n",
    "write_tweets(hrc, tweets)\n",
    "ilhan = \"IlhanMN\"\n",
    "write_tweets(ilhan, tweets)\n",
    "ppact = \"PPact\"\n",
    "write_tweets(ppact, tweets)\n",
    "gnew = \"GavinNewsom\"\n",
    "write_tweets(gnew, tweets)\n",
    "ted = \"RepTedLieu\"\n",
    "write_tweets(ted, tweets)\n",
    "eric = \"ericswalwell\"\n",
    "write_tweets(eric, tweets)\n",
    "kgil = \"SenGillibrand\"\n",
    "write_tweets(kgil, tweets)\n",
    "\n",
    "'''\n",
    "\n",
    "rep_handle1 = \"SenateGOP\"\n",
    "rep_handle2 = \"HouseGOP\"\n",
    "rep_handle3 = \"realDonaldTrump\"\n",
    "rep_handle4 = \"senatemajldr\"\n",
    "rep_handle5 = \"SpeakerRyan\"\n",
    "rep_handle6 = \"Heritage\"\n",
    "rep_handle7 = \"GOPChairwoman\"\n",
    "rep_handle8 = \"RepMattGaetz\"\n",
    "rep_handle9 = \"marcorubio\"\n",
    "rep_handle10 = \"WarrenDavidson\"\n",
    "rep_handle11 = \"GOPLeader\"\n",
    "rep_handle12= \"DLoesch\"\n",
    "rep_handle13 = \"SteveScalise\"\n",
    "rep_handle14 = \"March_For_Life\"\n",
    "rep_handle15 = \"charliekirk11\"\n",
    "rep_handle16 = \"SenatorTimScott\"\n",
    "rep_handle17 = \"SenMcSallyAZ\"\n",
    "rep_handle18 = \"TedCruz\"\n",
    "rep_handle19 = \"KellyannePolls\"\n",
    "\n",
    "write_tweets(rep_handle1, tweets)\n",
    "write_tweets(rep_handle2, tweets)\n",
    "write_tweets(rep_handle3, tweets)\n",
    "write_tweets(rep_handle4, tweets)\n",
    "write_tweets(rep_handle5, tweets)\n",
    "write_tweets(rep_handle6, tweets)\n",
    "write_tweets(rep_handle7, tweets)\n",
    "write_tweets(rep_handle8, tweets)\n",
    "write_tweets(rep_handle9, tweets)\n",
    "write_tweets(rep_handle10, tweets)\n",
    "write_tweets(rep_handle11, tweets)\n",
    "write_tweets(rep_handle12, tweets)\n",
    "write_tweets(rep_handle13, tweets)\n",
    "write_tweets(rep_handle14, tweets)\n",
    "write_tweets(rep_handle15, tweets)\n",
    "write_tweets(rep_handle16, tweets)\n",
    "write_tweets(rep_handle17, tweets)\n",
    "write_tweets(rep_handle18, tweets)\n",
    "write_tweets(rep_handle19, tweets)\n",
    "'''\n",
    "#republican_handle = \"SenateGOP\"\n",
    "\n",
    "\n",
    "\n",
    "#write_tweets(democrat_handle, tweets)\n",
    "#write_tweets(rep_handle, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
